{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-26T00:36:31.002045Z","iopub.execute_input":"2022-08-26T00:36:31.002590Z","iopub.status.idle":"2022-08-26T00:36:31.013459Z","shell.execute_reply.started":"2022-08-26T00:36:31.002545Z","shell.execute_reply":"2022-08-26T00:36:31.012270Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\ndata = data.fillna(0)\n\ndata.head()\n\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:36:43.988994Z","iopub.execute_input":"2022-08-26T00:36:43.989456Z","iopub.status.idle":"2022-08-26T00:36:44.034346Z","shell.execute_reply.started":"2022-08-26T00:36:43.989419Z","shell.execute_reply":"2022-08-26T00:36:44.033068Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\n\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:36:44.582109Z","iopub.execute_input":"2022-08-26T00:36:44.582522Z","iopub.status.idle":"2022-08-26T00:36:44.593484Z","shell.execute_reply.started":"2022-08-26T00:36:44.582488Z","shell.execute_reply":"2022-08-26T00:36:44.592305Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"categorical_columns = [\"HomePlanet\", \"Destination\"]\n\nboolean_columns = [\"CryoSleep\", \"VIP\"]\n\nnumerical_columns = [ \"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n\nall_columns = numerical_columns + boolean_columns + categorical_columns\n\nX = data[all_columns]\n\nY = data.Transported.astype(int)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:36:46.945603Z","iopub.execute_input":"2022-08-26T00:36:46.946023Z","iopub.status.idle":"2022-08-26T00:36:46.956985Z","shell.execute_reply.started":"2022-08-26T00:36:46.945986Z","shell.execute_reply":"2022-08-26T00:36:46.955756Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"def one_hot_encode(data, col):\n    one_hot_columns = pd.DataFrame()\n\n    unique = list(data[col].unique())\n\n    for value in unique:\n        one_hot_columns[value] = (data[col] == value).astype(int)\n    \n    return one_hot_columns\n\ndef shuffle_data(X, Y):\n\n    indexes = list(X.index)\n\n    np.random.shuffle(indexes)\n\n    shuffled_X = X.loc[indexes]\n    shuffled_Y = Y.loc[indexes]\n\n    return shuffled_X, shuffled_Y\n\ndef train_dev_split(X, Y):\n    m = X.shape[0]\n\n    train_size = np.floor(m * 0.7).astype(int)\n    dev_size = np.floor(m*0.3).astype(int)\n\n    X_train = X.iloc[:train_size]\n    Y_train = Y.iloc[:train_size]\n\n    X_dev = X.iloc[train_size:dev_size+train_size]\n    Y_dev = Y.iloc[train_size:dev_size+train_size]\n\n    return X_train, Y_train, X_dev, Y_dev\n\ndef normalize_input(X, epsilon=1e-8):\n\n    mean = np.mean(X)\n    variance = np.var(X)\n\n    return (X-mean) / np.sqrt(variance + epsilon)\n    # return X / np.max(X)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:36:49.405432Z","iopub.execute_input":"2022-08-26T00:36:49.405812Z","iopub.status.idle":"2022-08-26T00:36:49.417073Z","shell.execute_reply.started":"2022-08-26T00:36:49.405780Z","shell.execute_reply":"2022-08-26T00:36:49.416063Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def preprocess(X, Y):\n    X = X[all_columns]\n    for col in categorical_columns:\n        one_hot = one_hot_encode(X, col)\n\n        X = pd.concat([X, one_hot], axis=1)\n    \n    X = X.drop(categorical_columns, axis=1)\n\n    X[boolean_columns] = X[boolean_columns].astype(int)\n    \n    # normalising numerical columns\n    X[numerical_columns] = normalize_input(X[numerical_columns])\n\n    if Y is None:\n        return X.values.T\n\n    return X.values.T, Y.values.reshape(1, -1)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:36:53.936379Z","iopub.execute_input":"2022-08-26T00:36:53.937079Z","iopub.status.idle":"2022-08-26T00:36:53.943645Z","shell.execute_reply.started":"2022-08-26T00:36:53.937031Z","shell.execute_reply":"2022-08-26T00:36:53.942767Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"X, Y = shuffle_data(X, Y)\nX_train, Y_train, X_dev, Y_dev = train_dev_split(X, Y)\n\nprint(X_train.head())\nX_train, Y_train = preprocess(X_train, Y_train)\nX_dev, Y_dev = preprocess(X_dev, Y_dev)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:38:57.397513Z","iopub.execute_input":"2022-08-26T00:38:57.398306Z","iopub.status.idle":"2022-08-26T00:38:57.472988Z","shell.execute_reply.started":"2022-08-26T00:38:57.398257Z","shell.execute_reply":"2022-08-26T00:38:57.471542Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:38:59.461536Z","iopub.execute_input":"2022-08-26T00:38:59.462951Z","iopub.status.idle":"2022-08-26T00:38:59.473097Z","shell.execute_reply.started":"2022-08-26T00:38:59.462892Z","shell.execute_reply":"2022-08-26T00:38:59.471394Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"def gen_random_parameters(n_x, layers):\n    \"\"\"\n        Generate Random Parameters\n    \"\"\"\n\n    parameters = list()\n\n    L = len(layers)\n    \n    initializer = tf.initializers.GlorotNormal()\n\n    for l, layer in enumerate(layers):\n\n        n_a_prev = n_x if l == 0 else layers[l-1][0]\n\n        n_l, activation = layer\n\n        shape = (n_l, n_a_prev)\n        \n        if activation == 'dropout':\n            W = tf.Variable(np.random.randn(*shape) // 0.6, name=f\"dropout{l+1}\", dtype=tf.float32)\n            b = tf.zeros(shape=(n_l, 1))\n            b = tf.cast(b, tf.float32)\n        else:\n\n            W = tf.Variable(initializer(shape=shape) * .01, name=f'W{l+1}', dtype=tf.float32)\n\n            b = tf.Variable(initializer(shape=(n_l, 1)), name=f'b{l+1}', dtype=tf.float32)\n\n        parameters.append({'W': W, 'b': b, 'activation': activation})\n\n    return parameters\n\ndef forward_propagation_step(X, W, b, activation):\n    \"\"\"\n        Single Forward prop from A[l-1] across W[l]\n    \"\"\"\n    Z = tf.matmul(W, X) + b\n    \n    if activation == 'sigmoid':\n        A = tf.sigmoid(Z)\n    elif activation == 'tanh':\n        A = tf.tanh(Z)\n    elif activation == 'softmax':\n        A = tf.softmax(Z)\n    else:\n        A = tf.nn.relu(Z)\n\n    return tf.cast(A, tf.float32)\n\ndef forward_propagation(X, parameters):\n    \"\"\"\n        Full Forward propagation\n    \"\"\"\n    A_prev = tf.cast(X, tf.float32)\n\n    for param in parameters:\n\n        A_prev = forward_propagation_step(A_prev, **param)\n\n    return A_prev\n\n\ndef compute_cost(A, Y):\n    Y = tf.cast(Y, tf.float32)\n    # logprob = (tf.multiply(Y, tf.math.log(A)) + tf.multiply(1-Y, tf.math.log(1-A))) * -1\n    \n    loss = tf.keras.losses.binary_crossentropy(Y, A)\n\n    return loss\n","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:39:00.329674Z","iopub.execute_input":"2022-08-26T00:39:00.330079Z","iopub.status.idle":"2022-08-26T00:39:00.344377Z","shell.execute_reply.started":"2022-08-26T00:39:00.330045Z","shell.execute_reply":"2022-08-26T00:39:00.343145Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"\ndef run_epoch(X, Y, layers, parameters, optimizer, learning_rate=.01):\n\n    with tf.GradientTape() as tape:\n        # Forward Propagation\n        A = forward_propagation(X, parameters)\n\n        cost = compute_cost(A, Y)\n\n\n    weights = [(param['W'])  for param in parameters if param['activation'] != 'dropout']\n    biases = [(param['b'])  for param in parameters if param['activation'] != 'dropout']\n\n    trainable_variables = weights + biases\n\n    # Back Propagation\n    grads = tape.gradient(cost, trainable_variables)\n\n    # Gradient Descent step\n    optimizer.apply_gradients(zip(grads, trainable_variables))\n\n\n    return cost","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:39:01.288458Z","iopub.execute_input":"2022-08-26T00:39:01.288859Z","iopub.status.idle":"2022-08-26T00:39:01.296858Z","shell.execute_reply.started":"2022-08-26T00:39:01.288826Z","shell.execute_reply":"2022-08-26T00:39:01.295972Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"def train(X, Y, batch_size=5000, learning_rate=.1, print_cost=True):\n    layers = [\n        (16, 'relu'),\n        (16, 'relu'),\n        (8, 'relu'),\n        (8, 'relu'),\n        (16, 'relu'),\n        (1, 'sigmoid') # Output layer with sigmoid activation function\n    ]\n\n    parameters = gen_random_parameters(X.shape[0], layers)\n\n    X = tf.constant(X)\n    Y = tf.constant(Y)\n\n    # optimizer = tf.optimizers.Adam(learning_rate)\n    optimizer = tf.optimizers.Adam(learning_rate)\n\n    costs = []\n    accuracy = tf.keras.metrics.Accuracy()\n\n    for i in range(batch_size+1):\n\n        cost = run_epoch(X, Y, layers, parameters, optimizer, learning_rate)\n        costs.append(cost)\n\n\n        if i % 1000 == 0:\n            if print_cost:\n                print(f\"After {i}th epoch, cost is: {cost}\")\n            # learning_rate = decay_alpha(learning_rate, i)\n\n\n    accuracy.update_state(predict(X, parameters), Y)\n    print(f\"Accuracy is {accuracy.result().numpy()}%\")\n    \n    return parameters, costs\n\n\ndef decay_alpha(learning_rate, epoch_number, decay_rate=1e-8):\n\n    learning_rate = (1 / (1 + (decay_rate * epoch_number))) * learning_rate\n\n    return learning_rate\n\ndef predict(X, parameters):\n    A = forward_propagation(X, parameters)\n\n    return A // 0.5\n\ndef test_accuracy(X, Y, parameters):\n    accuracy = tf.keras.metrics.Accuracy()\n\n    accuracy.update_state(predict(X, parameters), Y)\n    \n    return accuracy.result().numpy()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:39:02.023836Z","iopub.execute_input":"2022-08-26T00:39:02.024862Z","iopub.status.idle":"2022-08-26T00:39:02.038135Z","shell.execute_reply.started":"2022-08-26T00:39:02.024808Z","shell.execute_reply":"2022-08-26T00:39:02.037243Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.1\nparameters, costs = train(X_train, Y_train, learning_rate=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:40:34.983419Z","iopub.execute_input":"2022-08-26T00:40:34.984167Z","iopub.status.idle":"2022-08-26T00:41:51.717405Z","shell.execute_reply.started":"2022-08-26T00:40:34.984116Z","shell.execute_reply":"2022-08-26T00:41:51.715416Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"plt.plot(list(range(0, 5000)), costs[0:5000])","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:42:38.888885Z","iopub.execute_input":"2022-08-26T00:42:38.889911Z","iopub.status.idle":"2022-08-26T00:42:39.090939Z","shell.execute_reply.started":"2022-08-26T00:42:38.889861Z","shell.execute_reply":"2022-08-26T00:42:39.089563Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"(10**np.abs(-np.random.randn(4)))","metadata":{"execution":{"iopub.status.busy":"2022-08-20T17:47:34.965152Z","iopub.execute_input":"2022-08-20T17:47:34.966445Z","iopub.status.idle":"2022-08-20T17:47:34.974690Z","shell.execute_reply.started":"2022-08-20T17:47:34.966390Z","shell.execute_reply":"2022-08-20T17:47:34.973618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_accuracy(X_dev, Y_dev, parameters)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:42:44.153572Z","iopub.execute_input":"2022-08-26T00:42:44.153965Z","iopub.status.idle":"2022-08-26T00:42:44.169329Z","shell.execute_reply.started":"2022-08-26T00:42:44.153933Z","shell.execute_reply":"2022-08-26T00:42:44.168243Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\").fillna(0)\n\ntest_data.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:42:47.987708Z","iopub.execute_input":"2022-08-26T00:42:47.988139Z","iopub.status.idle":"2022-08-26T00:42:48.037106Z","shell.execute_reply.started":"2022-08-26T00:42:47.988101Z","shell.execute_reply":"2022-08-26T00:42:48.035316Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:42:52.071684Z","iopub.execute_input":"2022-08-26T00:42:52.072113Z","iopub.status.idle":"2022-08-26T00:42:52.081219Z","shell.execute_reply.started":"2022-08-26T00:42:52.072077Z","shell.execute_reply":"2022-08-26T00:42:52.079940Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"X_test = preprocess(test_data, None)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:42:52.892058Z","iopub.execute_input":"2022-08-26T00:42:52.892946Z","iopub.status.idle":"2022-08-26T00:42:52.924937Z","shell.execute_reply.started":"2022-08-26T00:42:52.892901Z","shell.execute_reply":"2022-08-26T00:42:52.924089Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"X_test.shape\nparameters[0]['W'].shape","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:43:06.352286Z","iopub.execute_input":"2022-08-26T00:43:06.352983Z","iopub.status.idle":"2022-08-26T00:43:06.360568Z","shell.execute_reply.started":"2022-08-26T00:43:06.352930Z","shell.execute_reply":"2022-08-26T00:43:06.359272Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"prediction = predict(X_test, parameters)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:43:07.767113Z","iopub.execute_input":"2022-08-26T00:43:07.767547Z","iopub.status.idle":"2022-08-26T00:43:07.776986Z","shell.execute_reply.started":"2022-08-26T00:43:07.767510Z","shell.execute_reply":"2022-08-26T00:43:07.776108Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"np.squeeze(prediction.numpy().astype(bool))","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:47:20.305736Z","iopub.execute_input":"2022-08-26T00:47:20.306585Z","iopub.status.idle":"2022-08-26T00:47:20.314572Z","shell.execute_reply.started":"2022-08-26T00:47:20.306532Z","shell.execute_reply":"2022-08-26T00:47:20.313373Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'PassengerId': test_data.PassengerId, \n    'Transported': np.squeeze(prediction.numpy().astype(bool))\n})","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:47:36.401263Z","iopub.execute_input":"2022-08-26T00:47:36.401660Z","iopub.status.idle":"2022-08-26T00:47:36.410959Z","shell.execute_reply.started":"2022-08-26T00:47:36.401626Z","shell.execute_reply":"2022-08-26T00:47:36.410020Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"out = submission.to_csv(index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:48:31.521367Z","iopub.execute_input":"2022-08-26T00:48:31.522337Z","iopub.status.idle":"2022-08-26T00:48:31.534765Z","shell.execute_reply.started":"2022-08-26T00:48:31.522288Z","shell.execute_reply":"2022-08-26T00:48:31.533610Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/working/output.csv\", \"w\") as f:\n    f.write(out)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T00:49:09.055835Z","iopub.execute_input":"2022-08-26T00:49:09.056630Z","iopub.status.idle":"2022-08-26T00:49:09.061570Z","shell.execute_reply.started":"2022-08-26T00:49:09.056588Z","shell.execute_reply":"2022-08-26T00:49:09.060641Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}